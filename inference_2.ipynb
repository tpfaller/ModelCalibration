{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import presets\n",
    "import numpy as np\n",
    "import calibration_utils\n",
    "\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from Calibrator import Calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "MODEL = 'mobilenet_v3_large'\n",
    "NUM_CLASSES = 2\n",
    "PATH = 'output/model_8.pth'\n",
    "\n",
    "model = torchvision.models.get_model(MODEL, weights=None, num_classes=NUM_CLASSES)\n",
    "state_dict = torch.load(PATH)\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.to(device)\n",
    "\n",
    "args = state_dict[\"args\"]\n",
    "traindir, valdir = \"data/train\", \"data/val\"\n",
    "interpolation = InterpolationMode(args.interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = presets.ClassificationPresetEval(\n",
    "                crop_size=args.val_crop_size,\n",
    "                resize_size=args.val_resize_size,\n",
    "                interpolation=interpolation,\n",
    "                backend=args.backend,\n",
    "                use_v2=args.use_v2,\n",
    "            )\n",
    "\n",
    "dataset_train = torchvision.datasets.ImageFolder(\n",
    "    traindir,\n",
    "    preprocessing,\n",
    ")\n",
    "train_sampler = torch.utils.data.SequentialSampler(dataset_train)\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=args.batch_size, sampler=train_sampler, num_workers=args.workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "dataset_val = torchvision.datasets.ImageFolder(\n",
    "    valdir,\n",
    "    preprocessing,\n",
    ")\n",
    "val_sampler = torch.utils.data.SequentialSampler(dataset_val)\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, batch_size=args.batch_size, sampler=val_sampler, num_workers=args.workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "calibrator = Calibrator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, calibrator):\n",
    "    with torch.inference_mode():\n",
    "        for image, target in data_loader:\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = model(image)\n",
    "\n",
    "            calibrator.update(output, target)\n",
    "    \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
